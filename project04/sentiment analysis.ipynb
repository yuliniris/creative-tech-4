{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9404921-64bf-433b-a0a8-e91b1dc681ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'ProsusAI/finbert'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713fab3-82b9-476b-8d1a-911ecabb8137",
   "metadata": {},
   "source": [
    "use the model FinBERT, https://huggingface.co/ProsusAI/finbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e9ff8f-635f-4db1-b342-d80c37bf31ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iris/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147caaa7-2dcc-4c6f-a05c-0773128e3bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63823683ae334249941cff6787b6a84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02faf0685aca4c6aab5e25526083023e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e9a2f-b07d-4818-bd3a-922a0372b54d",
   "metadata": {},
   "source": [
    "initialize the model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02bda996-c878-4913-909a-b6371daa516b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfe0e1289204c1aa64a71a7cfb50d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59663f7d2d5b48bc84b6c5b78d7db95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a637dc1cc204fb6b89b0d36c40b6c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2f129-5171-4eda-bc8e-4d8964ebb240",
   "metadata": {},
   "source": [
    "following steps:\n",
    "1. Tokenize\n",
    "2. Token IDs -> model\n",
    "3. Model activations -> probabilities (using Softmax)\n",
    "4. Argmax of those probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6616d2d8-a72c-459e-a077-0396f3e12349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given the recent downturn in stocks especially in tech which is likely to persist as yields keep going up, I thought it would be prudent to share the risks of investing in ARK ETFs, written up very nicely by [The Bear Cave](https://thebearcave.substack.com/p/special-edition-will-ark-invest-blow). The risks comes primarily from ARK's illiquid and very large holdings in small cap companies. ARK is forced to sell its holdings whenever its liquid ETF gets hit with outflows as is especially the case in market downturns. This could force very painful liquidations at unfavorable prices and the ensuing crash goes into a positive feedback loop leading into a death spiral enticing even more outflows and predatory shorts.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = (\"Given the recent downturn in stocks especially in tech which is likely to persist as yields keep going up, \"\n",
    "       \"I thought it would be prudent to share the risks of investing in ARK ETFs, written up very nicely by \"\n",
    "       \"[The Bear Cave](https://thebearcave.substack.com/p/special-edition-will-ark-invest-blow). The risks comes \"\n",
    "       \"primarily from ARK's illiquid and very large holdings in small cap companies. ARK is forced to sell its \"\n",
    "       \"holdings whenever its liquid ETF gets hit with outflows as is especially the case in market downturns. \"\n",
    "       \"This could force very painful liquidations at unfavorable prices and the ensuing crash goes into a \"\n",
    "       \"positive feedback loop leading into a death spiral enticing even more outflows and predatory shorts.\")\n",
    "\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338cc1d7-f0a8-4a3a-a586-e41d13660bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_plus(txt,max_length=512,\n",
    "                               truncation=True,\n",
    "                               padding= 'max_length',\n",
    "                               add_special_tokens=True,\n",
    "                               return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cd253-b758-472a-b28a-dbeeef3c9cd8",
   "metadata": {},
   "source": [
    "token and ID:\n",
    "\n",
    "[CLS] = 101\n",
    "[SEP] = 102\n",
    "[MASK] = 103\n",
    "[UNK] = 100\n",
    "[PAD] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc62345-8503-489a-a1d3-8816e523c927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0ba761-c5cb-47f4-acae-86d323afd423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2445,  1996,  3522,  2091, 22299,  1999, 15768,  2926,  1999,\n",
       "          6627,  2029,  2003,  3497,  2000, 29486,  2004, 16189,  2562,  2183,\n",
       "          2039,  1010,  1045,  2245,  2009,  2052,  2022, 10975, 12672,  3372,\n",
       "          2000,  3745,  1996, 10831,  1997, 19920,  1999, 15745,  3802, 10343,\n",
       "          1010,  2517,  2039,  2200, 19957,  2011,  1031,  1996,  4562,  5430,\n",
       "          1033,  1006, 16770,  1024,  1013,  1013,  1996,  4783,  2906, 27454,\n",
       "          1012,  4942,  9153,  3600,  1012,  4012,  1013,  1052,  1013,  2569,\n",
       "          1011,  3179,  1011,  2097,  1011, 15745,  1011, 15697,  1011,  6271,\n",
       "          1007,  1012,  1996, 10831,  3310,  3952,  2013, 15745,  1005,  1055,\n",
       "          5665, 18515, 21272,  1998,  2200,  2312,  9583,  1999,  2235,  6178,\n",
       "          3316,  1012, 15745,  2003,  3140,  2000,  5271,  2049,  9583,  7188,\n",
       "          2049,  6381,  3802,  2546,  4152,  2718,  2007,  2041, 12314,  2015,\n",
       "          2004,  2003,  2926,  1996,  2553,  1999,  3006,  2091, 22299,  2015,\n",
       "          1012,  2023,  2071,  2486,  2200,  9145, 28763,  2015,  2012,  4895,\n",
       "          7011, 14550,  3085,  7597,  1998,  1996, 13831,  5823,  3632,  2046,\n",
       "          1037,  3893, 12247,  7077,  2877,  2046,  1037,  2331, 12313,  4372,\n",
       "          4588,  2075,  2130,  2062,  2041, 12314,  2015,  1998, 21659,  9132,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e289038-6949-4b3e-95c7-507807fb5c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3484686b-eb13-4a8c-8a4d-314543e7d611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.8200,  2.4484,  0.0216]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5a2758-8f46-484e-b23e-eb86996f2415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8200,  2.4484,  0.0216]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1f056-1ce8-459e-981a-c2db2ff4eaff",
   "metadata": {},
   "source": [
    "using PyTorch, softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00010385-545d-4f6d-aac9-020e7426da21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4aab8e6-2c8b-404f-acea-4bde84720893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0127, 0.9072, 0.0801]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23b882b9-44bf-4166-a43d-4528a900fa86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs = F.softmax(output[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4ae233-9ff5-41ff-a38a-94e0d3268171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0127, 0.9072, 0.0801]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74812ec-9812-4577-bfee-68140d35ffac",
   "metadata": {
    "tags": []
   },
   "source": [
    "do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cedf0d4d-5181-469d-a1a9-7f28f72b2335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "959340b6-0372-43d0-b0fd-d883b9d56b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = torch.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3266254-2557-490f-970d-a454fdaa682a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0a9c1-2810-4809-9b78-0c97e42ed768",
   "metadata": {},
   "source": [
    "1. getting data via the Kaggle API\n",
    "2. input pipeline for TensorFlow\n",
    "3. build and train model\n",
    "4. make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f33378-b992-44f2-95af-49ecb89bca31",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb17c008-a9a7-4291-b4d8-3f5094daa93b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.12.tar.gz (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m985.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (1.26.18)\n",
      "Requirement already satisfied: bleach in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /Users/iris/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in /Users/iris/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/iris/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iris/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/iris/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.12-py3-none-any.whl size=102975 sha256=97ab9d7788bba85f8820906f2d2dd3b0d7aebbc2b43ef96ce2bbb007d4806f67\n",
      "  Stored in directory: /Users/iris/Library/Caches/pip/wheels/f3/eb/e9/819c2d9eac90204eec8579430759f75a1d6dbe4cd0b93f53bc\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.6.12\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b93f213-7658-4b15-abac-596ec6eca332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/iris/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46136146-e50e-4f30-9616-5359474809f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda47cd5-2b3d-4e1c-a5de-d4ea1953638f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api = KaggleApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eef826b-972e-4e3e-a41e-f884bd202c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/iris/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac81eb3-ede0-4401-a3d5-77810c97a272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# api.competition_download_file('sentiment-analysis-on-movie-reviews','test.tsv.zip',path='./')\n",
    "# api.competition_download_file('sentiment-analysis-on-movie-reviews','train.tsv.zip',path='./')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6609876-4f75-464c-9f04-500f53675b39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/iris/anaconda3/lib/python3.11/site-packages (1.6.12)\n",
      "Requirement already satisfied: six>=1.10 in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (1.26.18)\n",
      "Requirement already satisfied: bleach in /Users/iris/anaconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /Users/iris/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in /Users/iris/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/iris/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iris/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/iris/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047d7b60-5a0f-4504-8f69-0c35c31591d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# api.competition_download_file('sentiment-analysis-on-movie-reviews','test.tsv.zip',path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34baadff-cd9b-42bb-9a33-db5f2e2b79b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle import api\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a44a4c-f153-49dc-87fe-1053fb13aa86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494k/494k [00:00<00:00, 926kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api.competition_download_file('sentiment-analysis-on-movie-reviews', 'test.tsv.zip', path='./')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0aa136-5e09-4d1a-9826-c21b9388385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.28M/1.28M [00:01<00:00, 1.06MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api.competition_download_file('sentiment-analysis-on-movie-reviews', 'train.tsv.zip', path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f43b81f-e5ec-4239-a02d-c87e3d32f0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0dede5-44cc-4f9f-8050-26d4848f8b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./test.tsv.zip','r') as zipref:\n",
    "    zipref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c8f3cb-6f01-4b7e-9222-d81461d621f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./train.tsv.zip','r') as zipref:\n",
    "    zipref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c44a20-6f3e-4d14-8a4b-dd0b648fa8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959c0bc9-5397-4ea1-b0a1-8b2a1d1b0bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d42c86-0147-49c0-83e2-6e2b049e4909",
   "metadata": {},
   "source": [
    "phrase column: text data to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0fe9b7-25fe-4524-96b8-f28e6207235f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155984</th>\n",
       "      <td>155985</td>\n",
       "      <td>8540</td>\n",
       "      <td>... either you 're willing to go with this cla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155997</th>\n",
       "      <td>155998</td>\n",
       "      <td>8541</td>\n",
       "      <td>Despite these annoyances , the capable Claybur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156021</th>\n",
       "      <td>156022</td>\n",
       "      <td>8542</td>\n",
       "      <td>-LRB- Tries -RRB- to parody a genre that 's al...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>156032</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>156040</td>\n",
       "      <td>8544</td>\n",
       "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8529 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "63            64           2   \n",
       "81            82           3   \n",
       "116          117           4   \n",
       "156          157           5   \n",
       "...          ...         ...   \n",
       "155984    155985        8540   \n",
       "155997    155998        8541   \n",
       "156021    156022        8542   \n",
       "156031    156032        8543   \n",
       "156039    156040        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "63      This quiet , introspective and entertaining in...          4  \n",
       "81      Even fans of Ismail Merchant 's work , I suspe...          1  \n",
       "116     A positively thrilling combination of ethnogra...          3  \n",
       "156     Aggressive self-glorification and a manipulati...          1  \n",
       "...                                                   ...        ...  \n",
       "155984  ... either you 're willing to go with this cla...          2  \n",
       "155997  Despite these annoyances , the capable Claybur...          2  \n",
       "156021  -LRB- Tries -RRB- to parody a genre that 's al...          1  \n",
       "156031  The movie 's downfall is to substitute plot fo...          1  \n",
       "156039  The film is darkly atmospheric , with Herrmann...          2  \n",
       "\n",
       "[8529 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['SentenceId'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75aaf0e0-a829-4643-baab-bce3641729d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Sentiment'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34604cbf-ae5f-4fd2-ad2d-8fc7049f8db4",
   "metadata": {},
   "source": [
    "The sentiment labels:\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c120a882-1bde-4865-b744-884cf3449b87",
   "metadata": {},
   "source": [
    "tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4becebfc-7a12-467e-9b03-727c28da19cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74512701-b335-4651-9a08-2147bc7de938",
   "metadata": {},
   "source": [
    "number of samples: 156060\n",
    "number of tokens: 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4506663b-226d-4705-a247-5f13d46ea70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e42d6-e425-4087-ad2c-b36c416fa23c",
   "metadata": {},
   "source": [
    "initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "851d7cb9-5ea8-494b-975e-649e95f488c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d12965dade64b40a3c5ccb2c0ea1e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf3eaaaf5164e7c8a4582cdef6be7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6edf566f6c548f18979704b3f402908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ed31719-0c8f-4a12-9f19-9ce6f4bd1b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(df['Phrase'].tolist(), max_length=seq_len,\n",
    "                   truncation=True, padding='max_length',\n",
    "                   add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b143183-abb9-45d3-9a27-6fa7fd38ac99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfc8217c-5780-49fb-8ccf-54718080f43f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101, 22572, 12148, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552cd90-e693-4e10-91ee-84cd0244f728",
   "metadata": {},
   "source": [
    "it shows classified tokens at the start: 101\n",
    "sequences and padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71e51fad-ad00-47a3-86ce-07589bd2187c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8865d71-0cab-40ae-b6c4-b0ce7897c41a",
   "metadata": {},
   "source": [
    "it shows 1 and 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e17de-d078-4e97-bd50-ea698a62a5c7",
   "metadata": {},
   "source": [
    "save these arrays as numpy binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6962d2e8-a88d-4467-bcf1-8a4883a67d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdf76b24-ad2b-4ce2-a597-e3ab13d886ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('movie-xids.npy', 'wb') as f:\n",
    "    np.save(f,tokens['input_ids'])\n",
    "with open('movie-xmask.npy','wb') as f:\n",
    "    np.save(f,tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48348ad8-d6dc-4d90-aa90-5867cdadbce6",
   "metadata": {},
   "source": [
    "extract sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b01dd43-0e5f-4939-9e0a-9a0cbdaf8505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2fba450-7507-49cd-b1f6-0bb9dbb82481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "650add84-94cd-41dd-9229-928ff9599d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 3, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47c6f807-531a-412b-bcac-57fde6b24588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305a58f-f545-41b9-a19f-cf49dc76d0a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "if have label two, and then encode it:\n",
    "\n",
    "2 = [0,0,1,0,0]\n",
    "4 = [0,0,0,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9497287-d33a-4cfe-a4e6-7b038cd79f76",
   "metadata": {},
   "source": [
    "initialze a zero array\n",
    "call it labels, numpy, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6fcae55-32bb-4e50-ac63-5f882d05f953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((num_samples, arr.max()+1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d3dcd64-f7b8-4be0-871e-3ee930f61b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21ea488a-a852-4fa9-a965-de1df470dcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels[np.arange(num_samples), arr] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c19ece25-55d0-49fa-9eca-41430573d28b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfd1e193-40f6-4902-a502-35fa4e26ef3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('movie-labels.npy','wb') as f:\n",
    "    np.save(f,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22459d-d067-4c83-aced-54d1dfcf7330",
   "metadata": {},
   "source": [
    "build dataset, build TensorFlow input pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "456fcc6d-d09f-44a6-9c82-eca8b65a505c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d64e372e-f887-4feb-b81e-e25f08bde689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('movie-xids.npy','rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "822be90e-217a-421e-a75a-ac69b58fb096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('movie-xmask.npy','rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d0118cb-12a4-403d-9698-f13c5df4a0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('movie-labels.npy','rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "322028dd-e75d-43b1-aeeb-36c34f602f13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101, 22572, 12148, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f153efff-a179-49d3-a6b6-74e75638a225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffdb16c4-e980-4626-b5ee-cf00d27307e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15db79ec-3b51-460a-ba37-cf5eaabef889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ece1a62c-fe51-4ed7-8449-656b920f06c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2382d0ff-8ff5-40d3-afe2-f55c82826f00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd18ee1b-a776-4014-89d6-7863a36002f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m {input_ids, attention_mask}, outputs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_ids' is not defined"
     ]
    }
   ],
   "source": [
    "{input_ids, attention_mask}, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76e10462-7cd1-415f-971d-55c8e59c3e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids':input_ids,\n",
    "            'attention_mask':masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "055fbd5e-b55e-4c90-8c68-dc274d09d110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__map_func() missing 1 required positional argument: 'labels'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(map_func)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2299\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m map_op\u001b[38;5;241m.\u001b[39m_map_v2(\n\u001b[1;32m   2300\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2301\u001b[0m     map_func,\n\u001b[1;32m   2302\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m   2303\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m   2304\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[38;5;241m=\u001b[39minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[38;5;241m=\u001b[39muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m fn_factory()\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwargs, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m    697\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m wrapper_helper(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, ag_ctx)(\u001b[38;5;241m*\u001b[39mnested_args)\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__map_func() missing 1 required positional argument: 'labels'\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e7ad3de-41ca-46b7-aedf-40fb0dd4e642",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40153de1-50ff-4de6-a944-ca8261e07efa",
   "metadata": {},
   "source": [
    "create TensorFlow dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1b6e8-02cb-4cc8-ae55-07c935e66489",
   "metadata": {},
   "source": [
    "shuffle data and batch it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52484f99-5ef2-4b5f-bd68-d7b374f0db66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9aadd6ff-08c9-4a3f-88ae-3fbaab13b50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "735d2e13-ae91-41f6-a591-d6ea042a0cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3af328be-209e-4331-ac3a-5242477f0ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d52f7dc8-1581-4113-887a-e5e6a4be6206",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03fb1877-8ad3-4a84-80d9-9e011f3931da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9753.75"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape[0]/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c77a1208-5d9c-4478-8c75-8d5d9ae76e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8778"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((Xids.shape[0]/batch_size) * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e48772f2-8bcb-49fb-b1f9-8084c2c5065e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = int((Xids.shape[0]/batch_size) * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30f89a47-498a-4589-a006-6dac462b9695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds=dataset.take(size)\n",
    "val_ds=dataset.skip(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f38b64dc-a4e6-4285-8336-61261da667b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/8w/mpz_tvmj7b98g9wp3y5d2r3m0000gn/T/ipykernel_89492/589511803.py:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_ds, 'train')\n",
    "tf.data.experimental.save(val_ds,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b05d3f21-f9db-40a5-bbcc-9e45a8b24482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9c08cff-a889-4c07-ab74-5824f0d67208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "660c8891-8590-4451-a57d-402e579db40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec == val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a9b8fed-7f36-4add-8a0f-4515eda8d4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/8w/mpz_tvmj7b98g9wp3y5d2r3m0000gn/T/ipykernel_89492/2337151686.py:1: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.experimental.load('train', element_spec=train_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28a285db-5977-4744-aefd-fd629e52017b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481fcf9-0b7f-445a-83fc-4fc0fb9432c7",
   "metadata": {},
   "source": [
    "build model architecture for sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5dc3e5-6cc5-4993-a347-e220ff182776",
   "metadata": {},
   "source": [
    "initialize the Bert model, using TF auto model from pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e86e7a47-0261-4d01-bd81-f3053e9e7a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724c6013-745c-4905-bad2-a043431b4a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe7624f-1d95-42e2-82c0-1beda7d191ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108310272 (413.17 MB)\n",
      "Trainable params: 108310272 (413.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d4b632-ad0d-446b-815e-69df08ab7a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbf1483-8418-42ba-8e2b-88b6101eb76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8694088-8a6d-46b1-9b0c-01cbf8692243",
   "metadata": {},
   "source": [
    "pooled activations are 2D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab00c02-164b-471c-a7f2-d56fb877f278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df48e0-09f0-4859-97b9-4561221ca89c",
   "metadata": {},
   "source": [
    "two inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0165f981-fc0c-46f2-a921-a5ca7d4dd140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(512,),\n",
    "                                  name='input_ids',dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,),\n",
    "                                  name='attention_mask',dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818945a-f93b-41a4-b869-0de12716be6d",
   "metadata": {},
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd9aa47b-9073-4d90-884c-40b3655ff8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ca551-30b0-4f88-88ce-112a8199161f",
   "metadata": {},
   "source": [
    "classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24fa99b-7f94-4c09-b445-023fa2cea104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d62812-db41-46f5-a42f-d4e3e480b15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934abe3b-3eaf-4837-8fc8-e960343b2d20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fda5b3e176472794f2fc32af4664d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "inputs = tokenizer(\"Hello, world!\", return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "mask = inputs[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a61a73-0758-4ceb-8a9e-778a7a0126df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "\n",
    "outputs = bert(input_ids=input_ids, attention_mask=mask)\n",
    "\n",
    "\n",
    "embeddings = outputs[1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "629e6094-42b4-4b23-a5ee-d928cab8409a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_6' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_6' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m TFAutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m bert_outputs \u001b[38;5;241m=\u001b[39m bert_model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[input_ids, attention_mask], outputs\u001b[38;5;241m=\u001b[39moutputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_6' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_6' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, BertTokenizer\n",
    "\n",
    "\n",
    "input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "\n",
    "bert_model = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "\n",
    "bert_outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60cca8ac-f4c6-4f30-83f2-c5f7fd84ad2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized type for `outputs`: [[0.1500378  0.19578391 0.3150366  0.24438477 0.09475695]] (of type <class 'tensorflow.python.framework.ops.EagerTensor'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[input_ids, mask], outputs\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/model.py:141\u001b[0m, in \u001b[0;36mModel.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functional_init_arguments(args, kwargs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m Model:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional\u001b[38;5;241m.\u001b[39mFunctional(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(Model, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/tracking.py:28\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/functional.py:152\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen providing `outputs` as a list/tuple, all values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the list/tuple must be KerasTensors. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m including invalid value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m             )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, backend\u001b[38;5;241m.\u001b[39mKerasTensor):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type for `outputs`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(outputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    157\u001b[0m trainable \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)]):\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized type for `outputs`: [[0.1500378  0.19578391 0.3150366  0.24438477 0.09475695]] (of type <class 'tensorflow.python.framework.ops.EagerTensor'>)"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087df8aa-7a06-46ee-b8cb-a08a3ed2c40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "165c9f74-091c-4f71-9ab4-b93ccbac9488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b29cf03-cb1c-427e-b072-57f48592ee66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_5' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_5' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m bert \u001b[38;5;241m=\u001b[39m TFAutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m bert(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m bert_output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_5' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_5' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_ids = tf.keras.Input(shape=(None,), dtype='int32', name='input_ids')\n",
    "mask = tf.keras.Input(shape=(None,), dtype='int32', name='attention_mask')\n",
    "\n",
    "\n",
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "bert_output = bert(input_ids, attention_mask=mask)\n",
    "\n",
    "\n",
    "y = bert_output[0]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ac39c3-8ed9-48ca-b32e-f763965c761c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized type for `outputs`: [[0.1500378  0.19578391 0.3150366  0.24438477 0.09475695]] (of type <class 'tensorflow.python.framework.ops.EagerTensor'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[input_ids, mask], outputs\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/model.py:141\u001b[0m, in \u001b[0;36mModel.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functional_init_arguments(args, kwargs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m Model:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional\u001b[38;5;241m.\u001b[39mFunctional(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(Model, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/tracking.py:28\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/functional.py:152\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen providing `outputs` as a list/tuple, all values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the list/tuple must be KerasTensors. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m including invalid value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m             )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, backend\u001b[38;5;241m.\u001b[39mKerasTensor):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type for `outputs`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(outputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    157\u001b[0m trainable \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)]):\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized type for `outputs`: [[0.1500378  0.19578391 0.3150366  0.24438477 0.09475695]] (of type <class 'tensorflow.python.framework.ops.EagerTensor'>)"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f71fa68-3bfc-431b-bc92-db648457675b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_4' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_4' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m TFAutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m bert_model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[input_ids, attention_mask], outputs\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_4' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_4' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, BertTokenizer\n",
    "\n",
    " \n",
    "input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    " \n",
    "bert_model = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    " \n",
    "outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    " \n",
    "y = outputs.last_hidden_state\n",
    "\n",
    " \n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc0538d-69b1-450a-a1d0-6403f244026d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.09365723  0.0995256  -0.06050768 ... -0.16746983  0.27449405\n",
      "   -0.0958368 ]\n",
      "  [ 0.24421787 -0.11154351  0.5590989  ... -0.25736088  0.07066885\n",
      "    0.20786303]\n",
      "  [ 0.23000246  0.01287152  0.1385987  ...  0.07103999  0.08163989\n",
      "    0.02318791]\n",
      "  ...\n",
      "  [ 0.30151787  0.02781061  0.03054495 ...  0.16898547  0.03820023\n",
      "    0.01034464]\n",
      "  [-0.09027284  0.04579119  0.19450107 ... -0.06552316  0.25364813\n",
      "   -0.17275922]\n",
      "  [ 0.53403157  0.628784   -0.00852468 ... -0.17854846  0.88687205\n",
      "   -0.93741596]]], shape=(1, 9, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "example = tokenizer(\"Testing the BERT model.\", return_tensors=\"tf\")\n",
    "bert_output = bert_model(example['input_ids'], attention_mask=example['attention_mask'])\n",
    "print(bert_output.last_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eab9fb2-d725-43dd-815b-ae386b0d963f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "\n",
    "input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76fa4743-f6c2-43e7-8d27-60cbeb66833d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_bert_model_7' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_7' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m bert_model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m      4\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:513\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_7' (type TFBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for attention_mask.\n\nCall arguments received by layer 'tf_bert_model_7' (type TFBertModel):\n  • input_ids=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=input_ids>\n  • attention_mask=<KerasTensor shape=(None, None), dtype=int32, sparse=None, name=attention_mask>\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "pooled_output = outputs.pooler_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1cbc856-7775-4154-8c55-6ee3331c6a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pooled_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the Keras model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[input_ids, attention_mask], outputs\u001b[38;5;241m=\u001b[39m[pooled_output, last_hidden_state])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pooled_output' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the Keras model\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[pooled_output, last_hidden_state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84ffec-c394-4e6d-aa21-bca311524cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4495ed1-eba5-41bc-bfe0-3b5f4ed4cde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c04f9-40da-4a24-b7ee-89d295ce1306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ea889-dabd-40b9-bb58-1e9077d31fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0beab0-f18b-4612-b2a0-5bd1c266dfae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ffc8e-9ca6-452a-a23f-fe723012e13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
